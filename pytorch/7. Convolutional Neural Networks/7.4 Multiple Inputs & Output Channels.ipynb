{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Multiple Input Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # Iterate through the 0th dimension (channel) of K first, then add them up\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "# X.shape >>> torch.Size([2, 3, 3])\n",
    "# K.shape >>> torch.Size([2, 2, 2])\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of K, and each time, perform\n",
    "    # cross-correlation operations with input X. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a trivial convolution kernel with 3 output channels by concatenating the kernel tensor for K with K+1 and K+2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] - [ ] 2. Preliminaries\n",
    "- [ ]   - [ ] 2.1 Data Manipulation\n",
    "- [ ]   - [ ] 2.2 Data Preprocessing\n",
    "- [ ]   - [ ] 2.3 Linear Algebra\n",
    "- [ ]   - [ ] 2.4 Calculus\n",
    "- [ ] 2.5 Automatic Differentiation\n",
    "- [ ] 2.6 Probability & Statistics\n",
    "- [ ] 2.7 Documentation\n",
    "- [ ] 3.1 Linear Regression\n",
    "- [ ] 3.2 Object-Oriented Design for Implementation\n",
    "- [ ] 3.3 Synthetic Regression Data\n",
    "- [ ] 3.4 Linear Regression Implementation from Scratch\n",
    "- [ ] 3.5 Concise Implementation of Linear Regression\n",
    "- [ ] 3.7 Weight Decay\n",
    "- [ ] 4.2 MNIST\n",
    "- [ ] 4.3 Base Classification Model\n",
    "- [ ] 4.4 Softmax Regression\n",
    "- [ ] 4.5 Concise Implementation of Softmax Regression\n",
    "- [ ] 5.1 Multilayer Perceptrons\n",
    "- [ ] 5.2 Implementation of Multilayer Perceptrons\n",
    "- [ ] 5.4 Numerical Stability and Init\n",
    "- [ ] 5.6 Dropout\n",
    "- [ ] 5.7 Predicting House Prices on Kaggle\n",
    "- [ ] 6.1 Layers and Modules\n",
    "- [ ] 6.2 Parameters Management\n",
    "- [ ] 6.3 Parameters Initialization\n",
    "- [ ] 6.4 Lazy Initialization\n",
    "- [ ] 6.5 Custom Layers\n",
    "- [ ] 6.6 File I-O\n",
    "- [ ] 6.7 GPUs\n",
    "- [ ] 7.2 Convolutions for Images\n",
    "- [ ] 7.3 Padding and Stride\n",
    "- [ ] 7.4 Multiple Inputs & Output Channels\n",
    "- [ ] 7.6 LeNet\n",
    "- [ ] 8.1 AlexNet\n",
    "- [ ] 8.2 VGG\n",
    "- [ ] 8.3 NiN\n",
    "- [ ] 8.4 GoogLeNet\n",
    "- [ ] 8.5 Batch Normalization\n",
    "- [ ] 8.6 Resnet & ResNeXt\n",
    "- [ ] 8.7 DenseNet\n",
    "- [ ] 8.8 Designing Convolution Network Architectures\n",
    "- [ ] 9.1 Working with Sequences\n",
    "11.1 Queries, Keys, amd Values\n",
    "11.2 Attention Pooling by Similarity\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
